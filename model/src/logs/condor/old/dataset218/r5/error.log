Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "train.py", line 67, in <module>
    generator = Generator(noise_dim, block_vector_dim, feature_map_size).to(device)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/cluster/research-groups/deneke/minecraft-gan/dcgan_pyenv/lib64/python3.6/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "hypertrain.py", line 101, in <module>
    run_training(hyperparams, process_dict, max_duration)
  File "hypertrain.py", line 23, in run_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 78, in restart_training
    monitor_processes(process_dict, max_duration)
  File "hypertrain.py", line 55, in monitor_processes
    restart_training(proc_info['hyperparams'], process_dict, max_duration, proc_info.get('recursion_level', 0) + 1)
  File "hypertrain.py", line 74, in restart_training
    train_process = subprocess.Popen(cmd_train)
  File "/usr/lib64/python3.6/subprocess.py", line 729, in __init__
    restore_signals, start_new_session)
  File "/usr/lib64/python3.6/subprocess.py", line 1279, in _execute_child
    if os.path.dirname(executable):
  File "/usr/lib64/python3.6/posixpath.py", line 157, in dirname
    sep = _get_sep(p)
RecursionError: maximum recursion depth exceeded